# PDF Quiz Generator Configuration

# Queue Service Settings
queue_service:
  base_url: "https://advanced-swe-group-project-server-694826236118.us-east4.run.app"

# Storage Paths
storage:
  pdf_dir: "storage/pdfs"
  pages_dir: "storage/pages"
  results_dir: "storage/results"
  metadata_dir: "storage/metadata"

# LLM Service Settings
llm:
  # Provider: "openrouter" (default, real LLM via OpenRouter) or "mock"
  provider: "openrouter"
  
  # API Key (use environment variable for security)
  # Examples:
  #   - For OpenRouter: Set OPENROUTER_API_KEY environment variable
  #   - For mock mode: Leave as null
  api_key: ${OPENROUTER_API_KEY}
  
  # Model Selection
  # Use any model identifier supported by OpenRouter, for example:
  #   - "openai/gpt-4o-mini"
  #   - "meta-llama/llama-3.1-8b-instruct"
  # For mock mode you can leave this as-is.
  # In your shell before running the client, set the API key, for example:
  #   export OPENROUTER_API_KEY="sk-or-your-api-key"
  model: "openai/gpt-5.1-chat"
  
  # Questions per page
  max_questions_per_page: 5

# Worker Configuration
worker:
  # Seconds to wait between polls when queue is empty
  poll_interval: 2.0
  
  # Maximum retry attempts for failed tasks
  max_retries: 3
  
  # Exponential backoff multiplier (seconds)
  retry_backoff: 2.0

# Anki Output Configuration
anki:
  deck_name: "Quiz Deck"
  output_dir: "output"